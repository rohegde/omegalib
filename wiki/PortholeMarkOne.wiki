#summary Developement proposal and design for Porthole, the iOS implementation of OmegaViewer
#sidebar Sidebar
This document contains the Porthole application concept, timeline and developement notes.

<wiki:toc max_depth="2" />

= Introduction and Research Question =

  The Cave Automatic Virtual Environment [http://www.evl.uic.edu/pape/CAVE/ CAVE] and related research has shown that Virtual Environments (VE) can be an effective way to visualize, interact and manipulate scientific data.  Additionally devices that blend 2D/3D content into a single VE workstation, like [http://www.evl.uic.edu/core.php?mod=4&type=3&indi=335 Dynallax], allowing scientist to work in an autostereoscopic VE and a 2D workstation simultaneously.  This merging of 2D/3D content is taken a step further in the [http://www.evl.uic.edu/files/pdf/ISVC11_Febretti.pdf OmegaDesk] where 2D/3D interaction are also used simultaneously.  Additionally, the Scalable Adaptive Graphics Environment [http://www.evl.uic.edu/core.php?mod=4&type=1&indi=281 (SAGE)] and related research has shown that large display environments can be an effective way to collaborate and convey ideas.  With the creation of the [http://www.evl.uic.edu/core.php?mod=4&type=4&indi=782 3D Cyber-commons], visualizations generated from a VE can now be viewed in stereo on a large display environment that is suited for collaboration.  Currently there is no middleware to bridge these two technologies nor is there a simple methodology to transfer this data to a personal computer.

  Porthole is a middleware application that bridges these gaps by abstracting data from a VR application to a portable tablet device for easy manipulating and viewing. The data transferred to the tablet consist of a specification for a user interface, a stream of rendered images. Porthole allows applications to specify a user interface that is composed of supported GUI elements, namely: buttons, sliders and switches. This specification would help tie a GUI element, a slider, to a manipulation function within the application, a scale model function. These GUI elements in conjunction with multi-touch information generated by the tablet would signal the application to manipulate the data in the visualization. A constant stream of rendered images will give users visual feedback on the tablet device as they further manipulate the data with the GUI Elements.

= Message Passing Protocol =
  A message passing protocol was established in order to communicate between the VR Application and Porthole.  The diagram below outlines all the messages that are passed between the VR Application, running the OmegaAppServer, and Porthole, acting as Client on the iPad. The detailed protocol is outlined in this a pdf that can be downloaded [http://omegalib.googlecode.com/svn/wiki/PortholeMsgPassProtocol.pdf here].

<p align="middle"><img src="http://omegalib.googlecode.com/svn/wiki/portholeMsgPassing.png" width="450"/></p><p align="middle">
_^This is a generic outline of the messages exchanged between Porthole and the VR Application.^_
</p>

= VR Applications =
  The VR Application incorporate OmegaLib.  OmegaLib handle setting up the VR scene and generating the correct views.  One of the views will be polarized passive stereo for the VR device of choice and the other the view for the iPad for user feedback.  All device input will be abstracted by OmegaLib in order to manipulate the scene.  This includes the mouse and keyboard, the iPad GUI element inputs, iPad multi-touch input, and head tracker data.  Implementing a VR Application was fairly straight forward.  However generating the correct views for both the VR device and iPad simultaneously proved to be a bit of a challenge.  This will be elaborate on more shortly.

   In addition to the VR Application, the Omega Application Server Proxy was created to test the message passing between Porthole and Application Server.  Though this was a development tool, it can easy serve as a starting point when trying to understand how a program communicated with Porthole.  This would allow developers to extend Porthole to transfer other types of data.
   
	<p align="middle"><img src="http://omegalib.googlecode.com/svn/wiki/omegaporthole.png" width="400"/></p><p align="middle">
	_^Porthole and omegalib applications are developed independently. They communicate though a common protocol to share pixel data, gui elements, and input events.^_
	</p>
   

= Porthole Application =
  The Porthole Application has two main areas: the Free Interaction Area (FIA) and the Custom UI Area (CUA). The Free Interaction Area allow the user to freely manipulate the data via touch.  The iPad support translation, rotation, pinch and swipe gestures as well as simple touches.  A subset of these were used to demonstrate that manipulations made on the FIA were reflected on the VR Application running on the VR device.  Additionally the FIA had a thumbnail of the data being manipulated as feedback for the user. The Custom UI Area provided users with specified fileds that would allo for further data manipulation.  This section support iOS buttons, sliders, and switches.  The main hurdle was designing an architecture that fostered communication between the main application loop, FIA , CUA , and the TCP Socket connection.
 
	<p align="middle"><img src="http://omegalib.googlecode.com/svn/wiki/portholeconfigs.png" width="600"/></p><p align="middle">
	_^Porthole Supports various view configurations depending on the orientation of the device and the application gui.^_
	</p>

= Future Works =
  The short term future work focuses on releasing Porthole to the public.  This would involve clean up this code and packaging it.  Additionally, the Omega Application Server Proxy needs to be repackaged as an simple example for users to understand how to comunicate with Porthole.  

  Longer term future work would be to add in the transportation functionality.  Given the time allotted, the transportation of the resulting data was not feasible.   This would allow geometry data to be streamed to the iPad2 after a user was done with their manipulations.  The tablet can now be used to transport the  geometry data. Ideally the transportation can be to a number of places: a personal computer where further analysis can be done, a Cyber-commons work area were the data can be distributed to peers and discussed, or another VR device that offers different capabilities.  This would allow Porthole to bridge the gap between the various technologies described.


= List of proposed features =
 * The application will connect to a single iPad
    This was accomplished and extended to two iPads.
 * The user will be able to choose a 3d model from a list of available ones displayed on the iPad. The model will be visualized on the 3d display.
    This was accomplished.   
 * The application will support multi-touch input from the iPad and reflect those changes to the VR Application.
    This was simplified to match the VR Application and accomplished.     
 * The user will be able to open a secondary user interface on the iPad, and modify properties of the displayed model or of the scene. Supported properties:
    This was simplified to match the VR Application and accomplished.     
 * At any time, the user will be able to switch to another model.
    This was accomplished.
 * The entire system will be head tracked. Object manipulation will always happen with respect to the user view point.
    This was accomplished.

= One Page Project Management (OPPM) for OmegaViewer =
https://docs.google.com/spreadsheet/ccc?key=0Ak41PBgfmhF7dEM5ZEVpTTJZVThLTjhOTjdzM0tOUnc&hl=en_US#gid=0\end{abstract}